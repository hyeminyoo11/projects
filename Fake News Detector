1. Problem Statement
These days, classifying of misinformation and fake news has become a significant challenge
across media platforms. People depend on online news more today than traditional newspapers,
so the ability to distinguish between accurate news and fake news is critical. Fake news can
cause widespread misinformation, influence public opinion, harm reputations, and even impact
political, social, and economic stability. The rapid growth of online social networks has
accelerated the spread of fake news (Fake news, disinformation and misinformation in social
media: a review, Esma Aïmeur, Sabrine Amri, Gilles Brassard 2023). For example, during the
COVID-19 pandemic, misinformation from fake news was a major threat to public health. (Royal
Society Open Science, Vol.7, No.10 2020)
Manual fact-checking to verify news article can be extremely time consuming. This project’s goal
is to detect fake news efficiently by leveraging machine learning and natural language
processing techniques. This project assumes some patterns can be detected in fake news.
Ideally, if we can develop an automated system that can identify fake news in real-time, we can
help stop the spread of misinformation. The project will focus on using machine learning models
to classify content as either real or fake, thus providing a solution to stop the growing fake news
problem.
2. Data Source
o WEL Fake dataset (https://www.kaggle.com/datasets/saurabhshahane/fake-news-
classification)
This dataset contains 72,134 news articles with 35,028 real and 27,106 fake news. The news is
from Kaggle, McIntire, Reuters, and BuzzFeed Political.
The dataset contains 4 columns:
- Serial number (starting from 0)
- Title (about the text news heading)
- Text (about the news content)
- Label (0 = fake and 1 = real)
3. Methodology
The goal of this project is to demonstrate how we apply these methods in a real-world problem.
Data Preprocessing
Data preprocessing is critical step to ensure that the input text data is clean and standardized
for machine learning models. All of the special characters need to be removed, and the upper
characters are converted to lowercase for uniformity. Text data sometimes has multiple spaces
which also need to be removed. Common words such as “the”
“a”
“is”
“are” which do not have
,
,
,
significant meaning for the classification, are removed. Additionally, stemming is applied to
reduce words to their base forms such as “eating,
” which is converted to “eat”
. These
preprocessing steps ensure that the data is well-structured and suitable for feature extraction.
Feature Extraction
Since machine learning models require numerical data, feature extraction is necessary to
transform text information into a numerical information. In this project, the TF-IDF(Term
Frequency-Inverse Document Frequency) method was employed. The TF-IDF generates a sparse
matrix, where each element representing the frequency of words and weighting it based on its
importance across the dataset. This method can highlight words that are more meaningful for
distinguishing between fake and real news.
Model Development
To find the best-performing model, multiple machine learning algorithms are implemented and
compared in this project. Hyperparameter tuning of the models was conducted for each model to
optimize their performance, and cross-validation was used to aid with the validation of the
models.
• Logistic Regression
- Logistic Regression is suited for binary classification tasks such as fake news or not.
(Fake news : 0 Real news : 1)
• SVM(Support Vector Machines)
- SVM can identify the optimal hyperplane to separate the two classes.
• Naïve Bayes
- Naïve bayes is a probabilistic classifier that assumes independence between the
features, commonly used for text classification problems.
• Random Forest
- Random Forest is an ensemble model that has multiple decision trees to improve the
classification accuracy.
4. Evaluation and Final Results
Model Evaluation
Since we have limited amount of data, cross-validation was used in this project. The training
data and test data ratio will be 70:30. To evaluate the model performance, various matrices
were used for evaluation.
• Accuracy: The percentage of correctly classified datapoints
• Precision: The proportion of predicted fake news that is truly fake
• Recall: The proportion of actual fake news correctly identified by the model
• F1-Score: Combining mean of precision and recall
